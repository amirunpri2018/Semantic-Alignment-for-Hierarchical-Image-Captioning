## V1.4
## Abstract
Inspired by recent progress of hierarchical reinforcement learning and adversarial text generation, we introduce a hierarchical adversarial attention based model to generate natural language description of images. The model automatically learns to align the attention over images and subgoal vectors in the process of caption generation. We describe how we can train, use and understand the model by showing its performance on Flickr8k. We also visualize the subgoal vectors and attention over images during generation procedures.


<img src="./assets/architecture-page-001.jpg" align="center" style="width:100%">

## Authors

<table style="width:100% bgcolor:#FFFFFF" align="center">
  <tr>
    <th><img src="./assets/lsd.JPG" style="border-radius:50%;"/></th>
    <th><img src="./assets/fzy.JPG" style="border-radius:50%;"/></th> 
    <th><img src="./assets/spy.JPG" style="border-radius:50%;"/></th>
  </tr>
 Â <tr align="center">
    <th>Sidi Lu</th>
    <th>Zhiyong Fang</th>
    <th>Peiyao Sheng</th>
  </tr>
</table>

## Demo

<p><a href="https://www.youtube.com/watch?v=QJbCfhRkcyg"><img src="https://img.youtube.com/vi/QJbCfhRkcyg/0.jpg" align="center" alt="IMAGE ALT TEXT HERE" width="75%" /></a></p>

## Code
We provide source code on [Github](github.com/zhiyong1997/github-pages-test), including:
1. Train/Test code.
2. Visualization tool for attention mechanism.



